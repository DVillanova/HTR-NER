# HTR-NER
Experimentation with different tagging annotations in the George Washington [1], IAM [2] and HOME [3] databases. Additional output constraining techniques were developed for the HOME database, where nested Named Entities can appear. The line-level annotation for the George Washington and IAM databases has been obtained from the word-level annotation presented in [4].

The images for the George Washington dataset can be found in: https://fki.tic.heia-fr.ch/databases/washington-database

The images for the IAM dataset can be found in: https://fki.tic.heia-fr.ch/databases/iam-handwriting-database

The images for the HOME dataset can be found in: https://www.monasterium.net/mom/collections

The line-level Named Entity annotation for the George Washington and IAM datasets has been published on Zenodo: https://doi.org/10.5281/zenodo.7805128


References: 

[1] Tjong Kim Sang, E.F., Buchholz, S.: Introduction to the CoNLL-2000 shared task chunking. In: Fourth Conference on Computational Natural Language Learning and the Second Learning Language in Logic Workshop. pp. 127–132 (2000)

[2] Marti, U.V., Bunke, H.: The iam-database: an english sentence database for offline handwriting recognition. International Journal on Document Analysis and Recognition 5(1), 39–46 (2002)

[3] Boros, E., Romero, V., Maarand, M., Zenklov ́a, K., Kˇreˇckov ́a, J., Vidal, E., Stutzmann, D., Kermorvant, C.: A comparison of sequential and combined approaches for named entity recognition in a corpus of handwritten medieval charters. In: 2020 17th International Conference on Frontiers in Handwriting Recognition (ICFHR). pp. 79–84. IEEE (2020)

[4] Tüselmann, O., Wolf, F., Fink, G.A.: Are end-to-end systems really necessary for ner on handwritten document images? In: Lladós, J., Lopresti, D., Uchida, S. (eds.) Document Analysis and Recognition – ICDAR 2021. pp. 808–822. Springer International Publishing, Cham (2021)
